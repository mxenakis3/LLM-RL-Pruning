{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195840b4",
   "metadata": {},
   "source": [
    "## Load Interaction and Configs\n",
    "The interaction class allows the environment object and the agent object to interface with one another\n",
    "The interaction class is parameterized by a configuration file. This is where you define parameters for:\n",
    "\n",
    "AGENT: # hidden layers, # nodes per layer, size of memory, etc. \n",
    "\n",
    "INTERACTION: how many training episodes, type of epsilon decay, number of testing episodes, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fad3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9f3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DESIRED INTERACTION CLASS AND CONFIGURATION\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the parent directory (where `configs/` and `interactions/` are located)\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you should be able to import\n",
    "from interactions import dqn_interaction as dqn\n",
    "from configs.dqn_configs import interaction_example_lunarlander, agent_example_lunarlander, env_lunar_lander_config\n",
    "from configs.llm_dqn_configs import dqn_llm_agent_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3896b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize an interaction using this configuration\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dqn_interaction \u001b[38;5;241m=\u001b[39m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDQNInteraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction_configs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minteraction_example_lunarlander\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43magent_configs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43magent_example_lunarlander\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43menv_configs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menv_lunar_lander_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mllm_configs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdqn_llm_agent_configs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train an agent\u001b[39;00m\n\u001b[1;32m      8\u001b[0m train_scores, trained_agent \u001b[38;5;241m=\u001b[39m dqn_interaction\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/storage/ice1/5/9/mxenakis3/LLM-RL-Pruning/interactions/dqn_interaction.py:45\u001b[0m, in \u001b[0;36mDQNInteraction.__init__\u001b[0;34m(self, interaction_configs, agent_configs, env_configs, llm_configs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Initialize agents\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent \u001b[38;5;241m=\u001b[39m DeepQNetwork(config \u001b[38;5;241m=\u001b[39m agent_configs)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_agent \u001b[38;5;241m=\u001b[39m \u001b[43mChain_of_Thought\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mllm_configs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_system_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_configs\u001b[38;5;241m.\u001b[39msystem_message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/storage/ice1/5/9/mxenakis3/LLM-RL-Pruning/agents/llm_chain_of_thought_agent.py:11\u001b[0m, in \u001b[0;36mChain_of_Thought.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;66;03m# Initialize client\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m   \u001b[38;5;66;03m# self.client = get_model()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem_message \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39msystem_message\n",
      "File \u001b[0;32m~/.conda/envs/venv/lib/python3.10/site-packages/openai/_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Initialize an interaction using this configuration\n",
    "dqn_interaction = dqn.DQNInteraction(interaction_configs = interaction_example_lunarlander,\n",
    "                                     agent_configs = agent_example_lunarlander,\n",
    "                                     env_configs = env_lunar_lander_config,\n",
    "                                     llm_configs = dqn_llm_agent_configs)\n",
    "\n",
    "# Train an agent\n",
    "train_scores, trained_agent = dqn_interaction.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "test_scores = dqn_interaction.test(trained_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # Adjust figure size if needed\n",
    "fig.suptitle(f\"Lunar Lander DQN Training - Discount: {dqn_interaction.config.gamma}\")\n",
    "\n",
    "# Training plot\n",
    "ax1.plot(train_scores, color='r')\n",
    "ax1.set_title('Training')\n",
    "ax1.set_xlabel('Episodes')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.grid()\n",
    "\n",
    "# Testing plot\n",
    "ax2.plot(test_scores, color='b')\n",
    "ax2.set_title('Testing')\n",
    "ax2.set_xlabel('Episodes')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.grid()\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
